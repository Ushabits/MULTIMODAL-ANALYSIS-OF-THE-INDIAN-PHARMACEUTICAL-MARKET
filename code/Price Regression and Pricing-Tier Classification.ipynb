{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c192a810-6a11-40a6-b673-fe72ec8ac3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dosage_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">121,728</span> │ manu_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dosage_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emb_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ emb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ num_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,392</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tier_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dosage_input        │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m121,728\u001b[0m │ manu_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m128\u001b[0m │ dosage_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emb_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m106\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ emb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ num_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m27,392\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tier_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,244</span> (758.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m194,244\u001b[0m (758.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,476</span> (755.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,476\u001b[0m (755.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training (Classification First)...\n",
      "Epoch 1/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - loss: 0.9415 - price_output_loss: 1.0517 - price_output_mae: 0.7242 - tier_output_accuracy: 0.5821 - tier_output_loss: 0.8889 - val_loss: 0.7704 - val_price_output_loss: 0.6598 - val_price_output_mae: 0.5515 - val_tier_output_accuracy: 0.6703 - val_tier_output_loss: 0.7376 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.7409 - price_output_loss: 0.6051 - price_output_mae: 0.5212 - tier_output_accuracy: 0.6890 - tier_output_loss: 0.7107 - val_loss: 0.6835 - val_price_output_loss: 0.5402 - val_price_output_mae: 0.4794 - val_tier_output_accuracy: 0.7116 - val_tier_output_loss: 0.6570 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - loss: 0.6688 - price_output_loss: 0.5378 - price_output_mae: 0.4819 - tier_output_accuracy: 0.7258 - tier_output_loss: 0.6419 - val_loss: 0.6586 - val_price_output_loss: 0.5099 - val_price_output_mae: 0.4577 - val_tier_output_accuracy: 0.7258 - val_tier_output_loss: 0.6337 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 15ms/step - loss: 0.6229 - price_output_loss: 0.5021 - price_output_mae: 0.4610 - tier_output_accuracy: 0.7473 - tier_output_loss: 0.5978 - val_loss: 0.6535 - val_price_output_loss: 0.4945 - val_price_output_mae: 0.4496 - val_tier_output_accuracy: 0.7326 - val_tier_output_loss: 0.6292 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - loss: 0.5935 - price_output_loss: 0.4796 - price_output_mae: 0.4485 - tier_output_accuracy: 0.7599 - tier_output_loss: 0.5694 - val_loss: 0.6426 - val_price_output_loss: 0.4716 - val_price_output_mae: 0.4356 - val_tier_output_accuracy: 0.7370 - val_tier_output_loss: 0.6193 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - loss: 0.5713 - price_output_loss: 0.4629 - price_output_mae: 0.4391 - tier_output_accuracy: 0.7712 - tier_output_loss: 0.5481 - val_loss: 0.6355 - val_price_output_loss: 0.4656 - val_price_output_mae: 0.4297 - val_tier_output_accuracy: 0.7408 - val_tier_output_loss: 0.6125 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 0.5550 - price_output_loss: 0.4520 - price_output_mae: 0.4331 - tier_output_accuracy: 0.7782 - tier_output_loss: 0.5324 - val_loss: 0.6290 - val_price_output_loss: 0.4478 - val_price_output_mae: 0.4240 - val_tier_output_accuracy: 0.7448 - val_tier_output_loss: 0.6067 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 0.5394 - price_output_loss: 0.4414 - price_output_mae: 0.4271 - tier_output_accuracy: 0.7844 - tier_output_loss: 0.5173 - val_loss: 0.6405 - val_price_output_loss: 0.4466 - val_price_output_mae: 0.4188 - val_tier_output_accuracy: 0.7451 - val_tier_output_loss: 0.6185 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.5286 - price_output_loss: 0.4325 - price_output_mae: 0.4231 - tier_output_accuracy: 0.7897 - tier_output_loss: 0.5069 - val_loss: 0.6533 - val_price_output_loss: 0.4395 - val_price_output_mae: 0.4209 - val_tier_output_accuracy: 0.7422 - val_tier_output_loss: 0.6314 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.5174 - price_output_loss: 0.4232 - price_output_mae: 0.4177 - tier_output_accuracy: 0.7946 - tier_output_loss: 0.4962 - val_loss: 0.6400 - val_price_output_loss: 0.4277 - val_price_output_mae: 0.4124 - val_tier_output_accuracy: 0.7474 - val_tier_output_loss: 0.6187 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.5084 - price_output_loss: 0.4186 - price_output_mae: 0.4153 - tier_output_accuracy: 0.7981 - tier_output_loss: 0.4874 - val_loss: 0.6364 - val_price_output_loss: 0.4292 - val_price_output_mae: 0.4142 - val_tier_output_accuracy: 0.7486 - val_tier_output_loss: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.5007 - price_output_loss: 0.4129 - price_output_mae: 0.4122 - tier_output_accuracy: 0.8019 - tier_output_loss: 0.4800 - val_loss: 0.6437 - val_price_output_loss: 0.4318 - val_price_output_mae: 0.4127 - val_tier_output_accuracy: 0.7507 - val_tier_output_loss: 0.6225 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.4965 - price_output_loss: 0.4075 - price_output_mae: 0.4088 - tier_output_accuracy: 0.8037 - tier_output_loss: 0.4761 - val_loss: 0.6518 - val_price_output_loss: 0.4267 - val_price_output_mae: 0.4143 - val_tier_output_accuracy: 0.7496 - val_tier_output_loss: 0.6318 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 0.4885 - price_output_loss: 0.4008 - price_output_mae: 0.4055 - tier_output_accuracy: 0.8059 - tier_output_loss: 0.4685 - val_loss: 0.6391 - val_price_output_loss: 0.4107 - val_price_output_mae: 0.4114 - val_tier_output_accuracy: 0.7532 - val_tier_output_loss: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 0.4821 - price_output_loss: 0.3957 - price_output_mae: 0.4035 - tier_output_accuracy: 0.8092 - tier_output_loss: 0.4622 - val_loss: 0.6570 - val_price_output_loss: 0.4175 - val_price_output_mae: 0.4140 - val_tier_output_accuracy: 0.7483 - val_tier_output_loss: 0.6360 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - loss: 0.4767 - price_output_loss: 0.3938 - price_output_mae: 0.4024 - tier_output_accuracy: 0.8119 - tier_output_loss: 0.4570 - val_loss: 0.6530 - val_price_output_loss: 0.4176 - val_price_output_mae: 0.4106 - val_tier_output_accuracy: 0.7517 - val_tier_output_loss: 0.6325 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.4741 - price_output_loss: 0.3927 - price_output_mae: 0.4006 - tier_output_accuracy: 0.8129 - tier_output_loss: 0.4545 - val_loss: 0.6509 - val_price_output_loss: 0.4138 - val_price_output_mae: 0.4154 - val_tier_output_accuracy: 0.7515 - val_tier_output_loss: 0.6309 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m2975/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4664 - price_output_loss: 0.3942 - price_output_mae: 0.3997 - tier_output_accuracy: 0.8160 - tier_output_loss: 0.4467\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 0.4676 - price_output_loss: 0.3883 - price_output_mae: 0.3980 - tier_output_accuracy: 0.8152 - tier_output_loss: 0.4481 - val_loss: 0.6671 - val_price_output_loss: 0.4194 - val_price_output_mae: 0.4135 - val_tier_output_accuracy: 0.7532 - val_tier_output_loss: 0.6461 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.4476 - price_output_loss: 0.3675 - price_output_mae: 0.3846 - tier_output_accuracy: 0.8243 - tier_output_loss: 0.4291 - val_loss: 0.6484 - val_price_output_loss: 0.4017 - val_price_output_mae: 0.4020 - val_tier_output_accuracy: 0.7568 - val_tier_output_loss: 0.6287 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - loss: 0.4354 - price_output_loss: 0.3608 - price_output_mae: 0.3824 - tier_output_accuracy: 0.8295 - tier_output_loss: 0.4173 - val_loss: 0.6446 - val_price_output_loss: 0.3877 - val_price_output_mae: 0.3944 - val_tier_output_accuracy: 0.7612 - val_tier_output_loss: 0.6252 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.4297 - price_output_loss: 0.3582 - price_output_mae: 0.3799 - tier_output_accuracy: 0.8313 - tier_output_loss: 0.4118 - val_loss: 0.6494 - val_price_output_loss: 0.3961 - val_price_output_mae: 0.4014 - val_tier_output_accuracy: 0.7577 - val_tier_output_loss: 0.6297 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - loss: 0.4237 - price_output_loss: 0.3533 - price_output_mae: 0.3777 - tier_output_accuracy: 0.8344 - tier_output_loss: 0.4059 - val_loss: 0.6584 - val_price_output_loss: 0.3897 - val_price_output_mae: 0.3978 - val_tier_output_accuracy: 0.7594 - val_tier_output_loss: 0.6393 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.4221 - price_output_loss: 0.3536 - price_output_mae: 0.3784 - tier_output_accuracy: 0.8340 - tier_output_loss: 0.4044 - val_loss: 0.6483 - val_price_output_loss: 0.3842 - val_price_output_mae: 0.3937 - val_tier_output_accuracy: 0.7609 - val_tier_output_loss: 0.6295 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.4167 - price_output_loss: 0.3502 - price_output_mae: 0.3763 - tier_output_accuracy: 0.8367 - tier_output_loss: 0.3992 - val_loss: 0.6526 - val_price_output_loss: 0.3917 - val_price_output_mae: 0.3972 - val_tier_output_accuracy: 0.7625 - val_tier_output_loss: 0.6337 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.4139 - price_output_loss: 0.3483 - price_output_mae: 0.3752 - tier_output_accuracy: 0.8378 - tier_output_loss: 0.3964 - val_loss: 0.6465 - val_price_output_loss: 0.3820 - val_price_output_mae: 0.3923 - val_tier_output_accuracy: 0.7629 - val_tier_output_loss: 0.6284 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - loss: 0.4112 - price_output_loss: 0.3470 - price_output_mae: 0.3750 - tier_output_accuracy: 0.8383 - tier_output_loss: 0.3939 - val_loss: 0.6572 - val_price_output_loss: 0.3871 - val_price_output_mae: 0.3944 - val_tier_output_accuracy: 0.7615 - val_tier_output_loss: 0.6392 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - loss: 0.4080 - price_output_loss: 0.3471 - price_output_mae: 0.3743 - tier_output_accuracy: 0.8401 - tier_output_loss: 0.3906 - val_loss: 0.6529 - val_price_output_loss: 0.3785 - val_price_output_mae: 0.3908 - val_tier_output_accuracy: 0.7629 - val_tier_output_loss: 0.6342 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.4058 - price_output_loss: 0.3446 - price_output_mae: 0.3733 - tier_output_accuracy: 0.8415 - tier_output_loss: 0.3885 - val_loss: 0.6558 - val_price_output_loss: 0.3825 - val_price_output_mae: 0.3925 - val_tier_output_accuracy: 0.7636 - val_tier_output_loss: 0.6373 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 0.4037 - price_output_loss: 0.3427 - price_output_mae: 0.3723 - tier_output_accuracy: 0.8422 - tier_output_loss: 0.3865 - val_loss: 0.6585 - val_price_output_loss: 0.3771 - val_price_output_mae: 0.3912 - val_tier_output_accuracy: 0.7634 - val_tier_output_loss: 0.6401 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.4017 - price_output_loss: 0.3419 - price_output_mae: 0.3718 - tier_output_accuracy: 0.8425 - tier_output_loss: 0.3845 - val_loss: 0.6625 - val_price_output_loss: 0.3774 - val_price_output_mae: 0.3899 - val_tier_output_accuracy: 0.7626 - val_tier_output_loss: 0.6443 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - loss: 0.4025 - price_output_loss: 0.3415 - price_output_mae: 0.3719 - tier_output_accuracy: 0.8423 - tier_output_loss: 0.3854 - val_loss: 0.6571 - val_price_output_loss: 0.3749 - val_price_output_mae: 0.3892 - val_tier_output_accuracy: 0.7647 - val_tier_output_loss: 0.6387 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.3969 - price_output_loss: 0.3379 - price_output_mae: 0.3707 - tier_output_accuracy: 0.8441 - tier_output_loss: 0.3799 - val_loss: 0.6657 - val_price_output_loss: 0.3674 - val_price_output_mae: 0.3876 - val_tier_output_accuracy: 0.7633 - val_tier_output_loss: 0.6480 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10ms/step - loss: 0.3957 - price_output_loss: 0.3408 - price_output_mae: 0.3707 - tier_output_accuracy: 0.8458 - tier_output_loss: 0.3786 - val_loss: 0.6594 - val_price_output_loss: 0.3645 - val_price_output_mae: 0.3843 - val_tier_output_accuracy: 0.7642 - val_tier_output_loss: 0.6417 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.3965 - price_output_loss: 0.3389 - price_output_mae: 0.3702 - tier_output_accuracy: 0.8453 - tier_output_loss: 0.3795 - val_loss: 0.6644 - val_price_output_loss: 0.3679 - val_price_output_mae: 0.3864 - val_tier_output_accuracy: 0.7645 - val_tier_output_loss: 0.6462 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m2972/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3922 - price_output_loss: 0.3415 - price_output_mae: 0.3707 - tier_output_accuracy: 0.8467 - tier_output_loss: 0.3751\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.3944 - price_output_loss: 0.3387 - price_output_mae: 0.3701 - tier_output_accuracy: 0.8451 - tier_output_loss: 0.3774 - val_loss: 0.6669 - val_price_output_loss: 0.3716 - val_price_output_mae: 0.3893 - val_tier_output_accuracy: 0.7634 - val_tier_output_loss: 0.6489 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - loss: 0.3852 - price_output_loss: 0.3294 - price_output_mae: 0.3637 - tier_output_accuracy: 0.8492 - tier_output_loss: 0.3686 - val_loss: 0.6526 - val_price_output_loss: 0.3623 - val_price_output_mae: 0.3825 - val_tier_output_accuracy: 0.7687 - val_tier_output_loss: 0.6352 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.3795 - price_output_loss: 0.3260 - price_output_mae: 0.3617 - tier_output_accuracy: 0.8525 - tier_output_loss: 0.3631 - val_loss: 0.6656 - val_price_output_loss: 0.3637 - val_price_output_mae: 0.3835 - val_tier_output_accuracy: 0.7677 - val_tier_output_loss: 0.6480 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - loss: 0.3755 - price_output_loss: 0.3241 - price_output_mae: 0.3615 - tier_output_accuracy: 0.8533 - tier_output_loss: 0.3592 - val_loss: 0.6645 - val_price_output_loss: 0.3622 - val_price_output_mae: 0.3827 - val_tier_output_accuracy: 0.7683 - val_tier_output_loss: 0.6466 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 0.3715 - price_output_loss: 0.3232 - price_output_mae: 0.3605 - tier_output_accuracy: 0.8549 - tier_output_loss: 0.3553 - val_loss: 0.6667 - val_price_output_loss: 0.3580 - val_price_output_mae: 0.3807 - val_tier_output_accuracy: 0.7670 - val_tier_output_loss: 0.6488 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m2976/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3711 - price_output_loss: 0.3279 - price_output_mae: 0.3616 - tier_output_accuracy: 0.8548 - tier_output_loss: 0.3547\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - loss: 0.3699 - price_output_loss: 0.3220 - price_output_mae: 0.3605 - tier_output_accuracy: 0.8561 - tier_output_loss: 0.3537 - val_loss: 0.6688 - val_price_output_loss: 0.3615 - val_price_output_mae: 0.3823 - val_tier_output_accuracy: 0.7678 - val_tier_output_loss: 0.6507 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.3687 - price_output_loss: 0.3193 - price_output_mae: 0.3586 - tier_output_accuracy: 0.8560 - tier_output_loss: 0.3527 - val_loss: 0.6637 - val_price_output_loss: 0.3549 - val_price_output_mae: 0.3784 - val_tier_output_accuracy: 0.7692 - val_tier_output_loss: 0.6459 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 0.3622 - price_output_loss: 0.3151 - price_output_mae: 0.3559 - tier_output_accuracy: 0.8595 - tier_output_loss: 0.3464 - val_loss: 0.6634 - val_price_output_loss: 0.3540 - val_price_output_mae: 0.3780 - val_tier_output_accuracy: 0.7693 - val_tier_output_loss: 0.6455 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.3608 - price_output_loss: 0.3148 - price_output_mae: 0.3560 - tier_output_accuracy: 0.8592 - tier_output_loss: 0.3450 - val_loss: 0.6677 - val_price_output_loss: 0.3521 - val_price_output_mae: 0.3776 - val_tier_output_accuracy: 0.7710 - val_tier_output_loss: 0.6501 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.3587 - price_output_loss: 0.3150 - price_output_mae: 0.3563 - tier_output_accuracy: 0.8605 - tier_output_loss: 0.3429 - val_loss: 0.6633 - val_price_output_loss: 0.3549 - val_price_output_mae: 0.3789 - val_tier_output_accuracy: 0.7700 - val_tier_output_loss: 0.6455 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.3581 - price_output_loss: 0.3153 - price_output_mae: 0.3564 - tier_output_accuracy: 0.8611 - tier_output_loss: 0.3423 - val_loss: 0.6679 - val_price_output_loss: 0.3557 - val_price_output_mae: 0.3788 - val_tier_output_accuracy: 0.7691 - val_tier_output_loss: 0.6499 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.3548 - price_output_loss: 0.3138 - price_output_mae: 0.3555 - tier_output_accuracy: 0.8624 - tier_output_loss: 0.3391 - val_loss: 0.6678 - val_price_output_loss: 0.3556 - val_price_output_mae: 0.3787 - val_tier_output_accuracy: 0.7701 - val_tier_output_loss: 0.6499 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m2975/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3559 - price_output_loss: 0.3207 - price_output_mae: 0.3574 - tier_output_accuracy: 0.8617 - tier_output_loss: 0.3399\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.3550 - price_output_loss: 0.3152 - price_output_mae: 0.3560 - tier_output_accuracy: 0.8619 - tier_output_loss: 0.3392 - val_loss: 0.6670 - val_price_output_loss: 0.3540 - val_price_output_mae: 0.3780 - val_tier_output_accuracy: 0.7704 - val_tier_output_loss: 0.6491 - learning_rate: 1.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 15ms/step - loss: 0.3534 - price_output_loss: 0.3107 - price_output_mae: 0.3546 - tier_output_accuracy: 0.8624 - tier_output_loss: 0.3378 - val_loss: 0.6632 - val_price_output_loss: 0.3568 - val_price_output_mae: 0.3789 - val_tier_output_accuracy: 0.7707 - val_tier_output_loss: 0.6451 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - loss: 0.3515 - price_output_loss: 0.3101 - price_output_mae: 0.3543 - tier_output_accuracy: 0.8635 - tier_output_loss: 0.3360 - val_loss: 0.6665 - val_price_output_loss: 0.3543 - val_price_output_mae: 0.3777 - val_tier_output_accuracy: 0.7705 - val_tier_output_loss: 0.6485 - learning_rate: 6.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m2977/2977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 16ms/step - loss: 0.3512 - price_output_loss: 0.3110 - price_output_mae: 0.3542 - tier_output_accuracy: 0.8634 - tier_output_loss: 0.3356 - val_loss: 0.6646 - val_price_output_loss: 0.3538 - val_price_output_mae: 0.3772 - val_tier_output_accuracy: 0.7717 - val_tier_output_loss: 0.6466 - learning_rate: 6.2500e-05\n",
      "\n",
      "--- FINAL EVALUATION ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Tier Accuracy: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80     10666\n",
      "           1       0.69      0.71      0.70     10651\n",
      "           2       0.83      0.82      0.83     10430\n",
      "\n",
      "    accuracy                           0.78     31747\n",
      "   macro avg       0.78      0.78      0.78     31747\n",
      "weighted avg       0.78      0.78      0.78     31747\n",
      "\n",
      "Price MAE: ₹177.54\n"
     ]
    }
   ],
   "source": [
    "import os, re, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"indian_pharmaceutical_products_clean.csv\" \n",
    "RND = 42\n",
    "np.random.seed(RND)\n",
    "tf.random.set_seed(RND)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. LOAD & PREPROCESS (Standard)\n",
    "# ---------------------------------------------------------\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"Error: File {DATA_PATH} not found.\")\n",
    "else:\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    # Cleaning\n",
    "    def normalize_text(s):\n",
    "        s = re.sub(r'[\\(\\)\\[\\]\\{\\},;:/\\\\\\|\"]', ' ', str(s).lower())\n",
    "        return re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "    def parse_strength(s):\n",
    "        m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(mcg|mg|g|µg|iu)?', str(s).lower())\n",
    "        if not m: return 0.0\n",
    "        v = float(m.group(1)); unit = (m.group(2) or '').replace('µg','mcg')\n",
    "        return v/1000.0 if unit == 'mcg' else (v*1000.0 if unit == 'g' else v)\n",
    "\n",
    "    def parse_pack(size, unit):\n",
    "        try:\n",
    "            if not pd.isna(size): return int(size)\n",
    "        except: pass\n",
    "        m = re.search(r'(\\d+)', str(unit).lower())\n",
    "        return int(m.group(1)) if m else 1\n",
    "\n",
    "    df['brand_clean'] = df['brand_name'].apply(normalize_text)\n",
    "    df['strength_mg'] = df['primary_strength'].apply(parse_strength)\n",
    "    df['pack_num'] = df.apply(lambda r: parse_pack(r.get('pack_size', pd.NA), r.get('pack_unit','')), axis=1)\n",
    "    df['composition_text'] = (df['primary_ingredient'].fillna('') + ' ' + df['active_ingredients'].fillna('')).apply(normalize_text)\n",
    "    df['text_for_emb'] = (df['brand_clean'] + ' ' + df['composition_text'] + ' ' + df['dosage_form'].fillna('').astype(str).str.lower())\n",
    "\n",
    "    df = df[df['price_inr'].notna()].reset_index(drop=True)\n",
    "    df['price_tier'] = pd.qcut(df['price_inr'], q=3, labels=[0,1,2]).astype(int)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 2. FEATURE ENGINEERING\n",
    "    # ---------------------------------------------------------\n",
    "    MAX_VOCAB = 10000; SEQ_LEN = 30; EMBED_DIM = 64\n",
    "    vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=SEQ_LEN)\n",
    "    vectorizer.adapt(df['text_for_emb'].astype(str).values)\n",
    "    \n",
    "    inp = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    x = vectorizer(inp)\n",
    "    x = layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=EMBED_DIM, mask_zero=True)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x) \n",
    "    enc = models.Model(inp, x)\n",
    "    emb_vectors = enc.predict(df['text_for_emb'].astype(str).values, batch_size=1024, verbose=0)\n",
    "    \n",
    "    df['embedding'] = list(emb_vectors)\n",
    "    EMB_DIM = emb_vectors.shape[1]\n",
    "\n",
    "    le_man = LabelEncoder()\n",
    "    df['manufacturer'] = df['manufacturer'].fillna('unknown').astype(str)\n",
    "    manu_counts = df['manufacturer'].value_counts()\n",
    "    df['manu_group'] = df['manufacturer'].apply(lambda x: x if manu_counts[x] > 10 else 'other')\n",
    "    df['manu_id'] = le_man.fit_transform(df['manu_group'])\n",
    "    \n",
    "    le_dos = LabelEncoder()\n",
    "    df['dosage_id'] = le_dos.fit_transform(df['dosage_form'].fillna('unknown').astype(str))\n",
    "    \n",
    "    features_numeric = ['pack_num', 'strength_mg']\n",
    "    num_scaler = StandardScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[features_numeric] = num_scaler.fit_transform(df_scaled[features_numeric])\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. SPLIT & PREPARE\n",
    "    # ---------------------------------------------------------\n",
    "    train_df, temp_df = train_test_split(df_scaled, test_size=0.25, random_state=RND, stratify=df_scaled['price_tier'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RND, stratify=temp_df['price_tier'])\n",
    "\n",
    "    def make_inputs(d):\n",
    "        return {\n",
    "            'emb_input': np.vstack(d['embedding'].values).astype('float32'),\n",
    "            'manu_input': d['manu_id'].astype('int32').values,\n",
    "            'dosage_input': d['dosage_id'].astype('int32').values,\n",
    "            'num_input': d[features_numeric].astype('float32').values\n",
    "        }\n",
    "\n",
    "    X_train, X_val, X_test = make_inputs(train_df), make_inputs(val_df), make_inputs(test_df)\n",
    "\n",
    "    y_train_list = [train_df['price_tier'].values, np.log1p(train_df['price_inr'].values)]\n",
    "    y_val_list = [val_df['price_tier'].values, np.log1p(val_df['price_inr'].values)]\n",
    "    y_test_list = [test_df['price_tier'].values, np.log1p(test_df['price_inr'].values)]\n",
    "\n",
    "    # Weights\n",
    "    classes = np.unique(y_train_list[0])\n",
    "    cw = class_weight.compute_class_weight('balanced', classes=classes, y=y_train_list[0])\n",
    "    class_weight_dict = dict(enumerate(cw))\n",
    "    \n",
    "    sw_tier = np.array([class_weight_dict[y] for y in y_train_list[0]])\n",
    "    sw_price = np.ones(len(y_train_list[1]))\n",
    "    sample_weight_list = [sw_tier, sw_price]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. ARCHITECTURE: \"Classification First\" (Restored Original Depth)\n",
    "    # ---------------------------------------------------------\n",
    "    MANU_VOCAB = df_scaled['manu_id'].nunique() + 1\n",
    "    DOSAGE_VOCAB = df_scaled['dosage_id'].nunique() + 1\n",
    "\n",
    "    # Inputs\n",
    "    emb_in = layers.Input(shape=(EMB_DIM,), name='emb_input')\n",
    "    manu_in = layers.Input(shape=(), dtype='int32', name='manu_input')\n",
    "    dosage_in = layers.Input(shape=(), dtype='int32', name='dosage_input')\n",
    "    num_in = layers.Input(shape=(len(features_numeric),), dtype='float32', name='num_input')\n",
    "\n",
    "    # Embeddings\n",
    "    manu_emb = layers.Flatten()(layers.Embedding(MANU_VOCAB, 32)(manu_in))\n",
    "    dos_emb = layers.Flatten()(layers.Embedding(DOSAGE_VOCAB, 8)(dosage_in))\n",
    "\n",
    "    # --- THE ORIGINAL DEEP SHARED STRUCTURE (This got you 94%) ---\n",
    "    # We bring back the full depth to ensure classification features are learned deeply\n",
    "    x = layers.Concatenate()([emb_in, manu_emb, dos_emb, num_in])\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    shared_features = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # --- HEAD A: Tier (Direct connection) ---\n",
    "    tier_out = layers.Dense(3, activation='softmax', name='tier_output')(shared_features)\n",
    "\n",
    "    # --- HEAD B: Price (Side Branch) ---\n",
    "    # Small branch off the side. \n",
    "    price_branch = layers.Dense(32, activation='relu')(shared_features)\n",
    "    price_out = layers.Dense(1, activation='linear', name='price_output')(price_branch)\n",
    "\n",
    "    model = models.Model(inputs=[emb_in, manu_in, dosage_in, num_in], outputs=[tier_out, price_out])\n",
    "    model.summary()\n",
    "\n",
    "    # --- CRITICAL PART: LOSS WEIGHTING ---\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss={'tier_output': 'sparse_categorical_crossentropy', 'price_output': 'mse'},\n",
    "        \n",
    "        # STRATEGY: Focus 95% on Class, 5% on Price\n",
    "        # This prevents price gradients from ruining classification\n",
    "        loss_weights={'tier_output': 1.0, 'price_output': 0.05}, \n",
    "        \n",
    "        metrics={'tier_output': 'accuracy', 'price_output': 'mae'}\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. TRAINING\n",
    "    # ---------------------------------------------------------\n",
    "    class Monitor(callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if epoch % 5 == 0: gc.collect()\n",
    "            \n",
    "    es = callbacks.EarlyStopping(monitor='val_tier_output_accuracy', mode='max', patience=10, restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_tier_output_accuracy', mode='max', patience=4, factor=0.5, verbose=1)\n",
    "\n",
    "    print(\"Starting training (Classification First)...\")\n",
    "    history = model.fit(\n",
    "        x=X_train, y=y_train_list,\n",
    "        sample_weight=sample_weight_list,\n",
    "        validation_data=(X_val, y_val_list),\n",
    "        epochs=50,\n",
    "        batch_size=64, \n",
    "        callbacks=[es, rlr, Monitor()],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. RESULTS\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n--- FINAL EVALUATION ---\")\n",
    "    preds = model.predict(X_test, batch_size=1024)\n",
    "    \n",
    "    # Tier\n",
    "    acc = accuracy_score(y_test_list[0], np.argmax(preds[0], axis=1))\n",
    "    print(f\"Tier Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test_list[0], np.argmax(preds[0], axis=1)))\n",
    "    \n",
    "    # Price\n",
    "    pred_price = np.expm1(preds[1].flatten())\n",
    "    true_price = np.expm1(y_test_list[1])\n",
    "    mae = mean_absolute_error(true_price, pred_price)\n",
    "    print(f\"Price MAE: ₹{mae:.2f}\")\n",
    "    \n",
    "    model.save('final_multitask_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0972843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dosage_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">121,728</span> │ manu_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dosage_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emb_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ emb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ num_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,392</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tier_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dosage_input        │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m121,728\u001b[0m │ manu_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m128\u001b[0m │ dosage_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emb_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m106\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ emb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ num_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m27,392\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tier_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">581,198</span> (2.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m581,198\u001b[0m (2.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,476</span> (755.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,476\u001b[0m (755.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386,954</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m386,954\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
